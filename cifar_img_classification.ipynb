{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar_img_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "JlkXyLi_V_w6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Get the Data"
      ]
    },
    {
      "metadata": {
        "id": "OCq9LWwb3k7n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f209fc0b-74dc-4fcb-ce63-578f07f6c793"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tja4Sk93cIQi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f76dd84-f2e8-49b5-999a-8146f5121c79"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../content/gdrive/My Drive/Colab Notebooks\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../content/gdrive/My Drive/Colab Notebooks\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cifar_img_classification.ipynb', 'MNIST_data', 'mnist_ classification.ipynb', 'cifar-10-batches-py']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kNfgttQN1eq3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Put file path as a string here\n",
        "cifar_dir = '../content/gdrive/My Drive/Colab Notebooks/cifar-10-batches-py/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sIM5CQzaUJqg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The archive contains the files data_batch_1, data_batch_2, ..., data_batch_5, as well as test_batch. Each of these files is a Python \"pickled\" object produced with cPickle.\n",
        "\n",
        "### Load the Data. Use the Code Below to load the data:"
      ]
    },
    {
      "metadata": {
        "id": "F0JxCUHN4bWW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        cifar_dict = pickle.load(fo, encoding = 'bytes')\n",
        "    return cifar_dict "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IsOgpHBm4fUY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dirs = ['batches.meta', 'data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5', 'test_batch']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qEctZCgB4hkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_data = [0,1,2,3,4,5,6]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KC0To9v441dP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i, direc in zip(all_data, dirs):\n",
        "    all_data[i] = unpickle(cifar_dir + direc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KY7JqPjb47S0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_meta = all_data[0]\n",
        "batch_1 = all_data[1]\n",
        "batch_2 = all_data[2]\n",
        "batch_3 = all_data[3]\n",
        "batch_4 = all_data[4]\n",
        "batch_5 = all_data[5]\n",
        "batch_test = all_data[6]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LdxABHQdxegP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "ca19135a-8e8f-44bf-abeb-75b5050977f3"
      },
      "cell_type": "code",
      "source": [
        "batch_meta"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{b'label_names': [b'airplane',\n",
              "  b'automobile',\n",
              "  b'bird',\n",
              "  b'cat',\n",
              "  b'deer',\n",
              "  b'dog',\n",
              "  b'frog',\n",
              "  b'horse',\n",
              "  b'ship',\n",
              "  b'truck'],\n",
              " b'num_cases_per_batch': 10000,\n",
              " b'num_vis': 3072}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "sllptrFeUgm2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Why the 'b's in front of the string?** Bytes literals are always prefixed with 'b' or 'B'; they produce an instance of the bytes type instead of the str type. They may only contain ASCII characters; bytes with a numeric value of 128 or greater must be expressed with escapes.\n",
        "\n",
        "https://stackoverflow.com/questions/6269765/what-does-the-b-character-do-in-front-of-a-string-literal"
      ]
    },
    {
      "metadata": {
        "id": "SoVKTUu5UtEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03f7036b-333a-47fe-9ba5-550444769824"
      },
      "cell_type": "code",
      "source": [
        "batch_1.keys()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "h6hcrPiFUvrT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loaded in this way, each of the batch files contains a dictionary with the following elements:\n",
        "\n",
        "*   data -- a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
        "*   labels -- a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data.\n",
        "\n",
        "\n",
        "The dataset contains another file, called batches.meta. It too contains a Python dictionary object. It has the following entries:\n",
        "\n",
        "\n",
        "*   label_names -- a 10-element list which gives meaningful names to the numeric labels in the labels array described above. For example, label_names[0] == \"airplane\", label_names[1] == \"automobile\", etc."
      ]
    },
    {
      "metadata": {
        "id": "KRTBAmGVVqio",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Display single image form the dataset\n",
        "Grab a single image from the batch dataset"
      ]
    },
    {
      "metadata": {
        "id": "JbFY1c6DzT6i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BbEH-vNvz6WK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = batch_1[b'data'].reshape(10000, 3, 32, 32).transpose(0, 2, 3, 1).astype('uint8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6SSZYCSqz6fZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "random_img = X[np.random.randint(0, 10000)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qYBuni3d0CSC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "ab24a7fb-3d10-4edc-ebc1-60bdaa5593a8"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(random_img)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7faaa4a9c550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD5CAYAAAAOeCiTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7faaa4be5710>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ERLOAHzY50DQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper Functions for Dealing With Data"
      ]
    },
    {
      "metadata": {
        "id": "xtrZW5nF5uZr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function to one-hot encode the labels\n",
        "def one_hot_encode(vec, vals = 10):\n",
        "    n = len(vec)\n",
        "    out = np.zeros((n, vals))\n",
        "    out[range(n), vec] = 1\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AKDzwxk55_NH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cifar helper function includes setting up the training and test images and providing the next batch\n",
        "class CifarHelper():\n",
        "    def __init__(self):\n",
        "        self.i = 0\n",
        "        \n",
        "        self.training_set = [batch_1, batch_2, batch_3, batch_4, batch_5]\n",
        "        \n",
        "        self.test_set = [batch_test]\n",
        "        \n",
        "        self.train_images = None\n",
        "        self.train_labels = None\n",
        "        \n",
        "        self.test_images = None\n",
        "        self.test_labels = None\n",
        "        \n",
        "    def set_images(self):\n",
        "        # stacking the images vertical\n",
        "        self.train_images = np.vstack([batch[b'data'] for batch in self.training_set])\n",
        "        train_len = len(self.train_images)\n",
        "        \n",
        "        # reshaping the images in the training set and then transposing it\n",
        "        self.train_images = self.train_images.reshape(train_len, 3, 32, 32).transpose(0, 2, 3, 1)/255\n",
        "        \n",
        "        # one hot encoding the train labels\n",
        "        self.train_labels = one_hot_encode(np.hstack([batch[b'labels'] for batch in self.training_set]), 10)\n",
        "        \n",
        "        # Vertically stacking the test images\n",
        "        self.test_images = np.vstack([j[b'data'] for j in self.test_set])\n",
        "        test_len = len(self.test_images)\n",
        "        \n",
        "        # Reshaping the test images and then transposing the array\n",
        "        self.test_images = self.test_images.reshape(test_len, 3, 32, 32).transpose(0, 2, 3, 1)/255\n",
        "        \n",
        "        # one hot encoding the test labels\n",
        "        self.test_labels = one_hot_encode(np.hstack([j[b'labels'] for j in self.test_set]), 10)\n",
        "        \n",
        "    def next_batch(self, batch_size):\n",
        "        x = self.train_images[self.i : self.i + batch_size].reshape(100, 32, 32, 3)\n",
        "        y = self.train_labels[self.i : self.i + batch_size]\n",
        "        self.i = (self.i + batch_size) % len(self.train_images)\n",
        "        return x,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "akxRVpBK6Bue",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ch = CifarHelper()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j4_Z-lVi6EAP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ch.set_images()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DK4seu376GzS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Creating the model"
      ]
    },
    {
      "metadata": {
        "id": "r9kKffvn6PS6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lcK2GRgL6TW4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, shape = [None, 32, 32, 3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zF39wGVw6U6T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_true = tf.placeholder(tf.float32, shape = [None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yJvXKGqc6WdJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hold_prob = tf.placeholder(tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n6tokkRh6cKE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Helper functions for the model"
      ]
    },
    {
      "metadata": {
        "id": "x6XnBE5a6pVE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def init_weights(shape):\n",
        "    rand_weights = tf.truncated_normal(shape = shape, stddev = 1.0)\n",
        "    return tf.Variable(rand_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a6Wa19SD6tjS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def init_bias(shape):\n",
        "    bias = tf.constant(0.1, dtype = tf.float32, shape = shape)\n",
        "    return tf.Variable(bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1CQlodry6vfL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d(x, W):\n",
        "    return tf.nn.conv2d(x, W, strides = [1, 1, 1, 1], padding = 'SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "--kqQjJE6x2M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def max_pool_2by2(input_layer):\n",
        "    return tf.nn.max_pool(input_layer, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tp3uNWm-60f7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convolutional_layer(input_X, shape):\n",
        "    W = init_weights(shape)\n",
        "    b = init_bias([shape[3]])\n",
        "    return tf.nn.relu(conv2d(input_X, W) + b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5CUXycCf62tm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normal_full_layer(input_layer, size):\n",
        "    shape = input_layer.get_shape().as_list()[1]\n",
        "    W = init_weights([shape, size])\n",
        "    b = init_bias([size])\n",
        "    return tf.matmul(input_layer, W) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HRleqW_c64Mm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# starting the model\n",
        "\n",
        "# 1st convolutional layer\n",
        "convo_1 = convolutional_layer(X, shape = [4, 4, 3, 32])\n",
        "convo_1_pooled = max_pool_2by2(convo_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qmtH8xk565su",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 2nd convolutional layer\n",
        "convo_2 = convolutional_layer(convo_1_pooled, shape = [4, 4, 32, 64])\n",
        "convo_2_pooled = max_pool_2by2(convo_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "napsO0O2673g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now comes the falttening layer\n",
        "convo_2_flat = tf.reshape(convo_2_pooled, [-1, 8*8*64])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0AoL-GqW690g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Normal fully connected layer\n",
        "full_layer = tf.nn.relu(normal_full_layer(convo_2_flat, size = 1024))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BpQ2xEri6_IA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dropout layer\n",
        "full_drop_layer = tf.nn.dropout(full_layer, keep_prob = hold_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OvK4u_N67AYl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# predicting the labels\n",
        "y_pred = normal_full_layer(full_drop_layer, size = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sThOscBi7BuJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y_true, logits = y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a4wlSd_r7DNZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# setting up the optimizer\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pjjXjU767FzQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = optimizer.minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tt47H_yK7HJ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4A0xulzPZMOn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gpu_options = tf.GPUOptions(allow_growth=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2bgdlfpE7Icu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2554
        },
        "outputId": "14a181fe-d63a-4c32-ce7d-eb64351f9808"
      },
      "cell_type": "code",
      "source": [
        "# Graph Session\n",
        "\n",
        "accuracies = []\n",
        "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    for step in range(5000):\n",
        "        #Training the model\n",
        "        batch_X, batch_y = ch.next_batch(100)\n",
        "        sess.run(train, feed_dict = {X : batch_X, y_true: batch_y, hold_prob: 1.0})\n",
        "\n",
        "        if(step % 100 == 0):\n",
        "            print('Currently on step: {}'.format(step))\n",
        "            print('Accuracy :')\n",
        "            # Testing the model\n",
        "            equals = [tf.equal(tf.argmax(y_true, 1), tf.argmax(y_pred, 1))]\n",
        "            acc = tf.reduce_mean(tf.cast(equals, dtype = tf.float32))\n",
        "        \n",
        "            result= sess.run(acc, feed_dict = {X: ch.test_images, y_true: ch.test_labels, hold_prob: 1.0})\n",
        "            accuracies.append(result)\n",
        "            print(result)\n",
        "            \n",
        "    avg_accuracy = sum(accuracies)/len(accuracies)\n",
        "    print('Average Accuracy: {}'.format(avg_accuracy))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Currently on step: 0\n",
            "Accuracy :\n",
            "0.1\n",
            "Currently on step: 100\n",
            "Accuracy :\n",
            "0.2305\n",
            "Currently on step: 200\n",
            "Accuracy :\n",
            "0.2736\n",
            "Currently on step: 300\n",
            "Accuracy :\n",
            "0.3101\n",
            "Currently on step: 400\n",
            "Accuracy :\n",
            "0.3251\n",
            "Currently on step: 500\n",
            "Accuracy :\n",
            "0.3459\n",
            "Currently on step: 600\n",
            "Accuracy :\n",
            "0.3421\n",
            "Currently on step: 700\n",
            "Accuracy :\n",
            "0.3501\n",
            "Currently on step: 800\n",
            "Accuracy :\n",
            "0.3694\n",
            "Currently on step: 900\n",
            "Accuracy :\n",
            "0.3791\n",
            "Currently on step: 1000\n",
            "Accuracy :\n",
            "0.3779\n",
            "Currently on step: 1100\n",
            "Accuracy :\n",
            "0.389\n",
            "Currently on step: 1200\n",
            "Accuracy :\n",
            "0.391\n",
            "Currently on step: 1300\n",
            "Accuracy :\n",
            "0.398\n",
            "Currently on step: 1400\n",
            "Accuracy :\n",
            "0.4085\n",
            "Currently on step: 1500\n",
            "Accuracy :\n",
            "0.3985\n",
            "Currently on step: 1600\n",
            "Accuracy :\n",
            "0.4109\n",
            "Currently on step: 1700\n",
            "Accuracy :\n",
            "0.4134\n",
            "Currently on step: 1800\n",
            "Accuracy :\n",
            "0.4238\n",
            "Currently on step: 1900\n",
            "Accuracy :\n",
            "0.4191\n",
            "Currently on step: 2000\n",
            "Accuracy :\n",
            "0.4112\n",
            "Currently on step: 2100\n",
            "Accuracy :\n",
            "0.4233\n",
            "Currently on step: 2200\n",
            "Accuracy :\n",
            "0.4229\n",
            "Currently on step: 2300\n",
            "Accuracy :\n",
            "0.4332\n",
            "Currently on step: 2400\n",
            "Accuracy :\n",
            "0.4291\n",
            "Currently on step: 2500\n",
            "Accuracy :\n",
            "0.4201\n",
            "Currently on step: 2600\n",
            "Accuracy :\n",
            "0.4326\n",
            "Currently on step: 2700\n",
            "Accuracy :\n",
            "0.4314\n",
            "Currently on step: 2800\n",
            "Accuracy :\n",
            "0.4381\n",
            "Currently on step: 2900\n",
            "Accuracy :\n",
            "0.4353\n",
            "Currently on step: 3000\n",
            "Accuracy :\n",
            "0.4289\n",
            "Currently on step: 3100\n",
            "Accuracy :\n",
            "0.4407\n",
            "Currently on step: 3200\n",
            "Accuracy :\n",
            "0.4434\n",
            "Currently on step: 3300\n",
            "Accuracy :\n",
            "0.4465\n",
            "Currently on step: 3400\n",
            "Accuracy :\n",
            "0.4368\n",
            "Currently on step: 3500\n",
            "Accuracy :\n",
            "0.4395\n",
            "Currently on step: 3600\n",
            "Accuracy :\n",
            "0.4463\n",
            "Currently on step: 3700\n",
            "Accuracy :\n",
            "0.4552\n",
            "Currently on step: 3800\n",
            "Accuracy :\n",
            "0.453\n",
            "Currently on step: 3900\n",
            "Accuracy :\n",
            "0.451\n",
            "Currently on step: 4000\n",
            "Accuracy :\n",
            "0.4477\n",
            "Currently on step: 4100\n",
            "Accuracy :\n",
            "0.4503\n",
            "Currently on step: 4200\n",
            "Accuracy :\n",
            "0.4538\n",
            "Currently on step: 4300\n",
            "Accuracy :\n",
            "0.4554\n",
            "Currently on step: 4400\n",
            "Accuracy :\n",
            "0.4575\n",
            "Currently on step: 4500\n",
            "Accuracy :\n",
            "0.4566\n",
            "Currently on step: 4600\n",
            "Accuracy :\n",
            "0.4525\n",
            "Currently on step: 4700\n",
            "Accuracy :\n",
            "0.4587\n",
            "Currently on step: 4800\n",
            "Accuracy :\n",
            "0.4632\n",
            "Currently on step: 4900\n",
            "Accuracy :\n",
            "0.4636\n",
            "Average Accuracy: 0.40667599901556967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H3J43TZR7pKJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}